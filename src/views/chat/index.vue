<script setup lang='ts'>
import type { Ref } from 'vue'
import { computed, onMounted, onUnmounted, ref } from 'vue'
import { useRoute } from 'vue-router'
import { storeToRefs } from 'pinia'
import { NAutoComplete, NButton, NInput, useDialog, useMessage } from 'naive-ui'
import html2canvas from 'html2canvas'
import { MdEditor } from 'md-editor-v3'
import { Message } from './components'
import { useScroll } from './hooks/useScroll'
import { useChat } from './hooks/useChat'
import { useSocket } from './hooks/useSocket'
import { useUsingContext } from './hooks/useUsingContext'
import HeaderComponent from './components/Header/index.vue'
import { HoverButton, SvgIcon } from '@/components/common'
import { useBasicLayout } from '@/hooks/useBasicLayout'
import { CHAT_FRIENDS, CHAT_GPT, useAppStore, useChatStore, usePromptStore, useUserStore } from '@/store'
import { fetchChatAPIProcess } from '@/api'
import { t } from '@/locales'
import 'md-editor-v3/lib/style.css'

let controller = new AbortController()

const openLongReply = import.meta.env.VITE_GLOB_OPEN_LONG_REPLY === 'true'

const route = useRoute()
const dialog = useDialog()
const ms = useMessage()

const appStore = useAppStore()
const chatStore = useChatStore()
const userStore = useUserStore()

const { isMobile } = useBasicLayout()
const { addChat, updateChat, updateChatSome, getChatByUuidAndIndex } = useChat()
const { scrollRef, scrollToBottom, scrollToBottomIfAtBottom } = useScroll()
const { reconnect, emitSendMessage, onConnect, onReceiveMessage, onRoomNotExist, onUserJoined, onUserDisconnect, onUserLeft } = useSocket()
const { usingContext, toggleUsingContext } = useUsingContext()

const { uuid } = route.params as { uuid: string }

const dataSources = computed(() => chatStore.getChatByUuid(+uuid))
const conversationList = computed(() => dataSources.value.filter(item => (!item.inversion && !!item.conversationOptions)))

const prompt = ref<string>('')
const loading = ref<boolean>(false)
const inputRef = ref<Ref | null>(null)

// æ·»åŠ PromptStore
const promptStore = usePromptStore()

// ä½¿ç”¨storeToRefsï¼Œä¿è¯storeä¿®æ”¹åï¼Œè”æƒ³éƒ¨åˆ†èƒ½å¤Ÿé‡æ–°æ¸²æŸ“
const { promptList: promptTemplate } = storeToRefs<any>(promptStore)

const GPTnickName = 'GPT'
const chatTypeRef = ref<string | undefined>((chatStore.getChatHistoryByCurrentActive)?.chatType)
const activeUuid = ref((chatStore.getChatHistoryByCurrentActive)?.uuid)
const currentChat = chatStore.getChatFromSession(activeUuid.value)!
const theme = computed(() => appStore.theme === 'auto' ? 'light' : appStore.theme)

// æœªçŸ¥åŸå› åˆ·æ–°é¡µé¢ï¼Œloading çŠ¶æ€ä¸ä¼šé‡ç½®ï¼Œæ‰‹åŠ¨é‡ç½®
dataSources.value.forEach((item, index) => {
  if (item.loading)
    updateChatSome(+uuid, index, { loading: false })
})

function handleSubmit() {
  const currentChatType = chatStore.getChatHistoryByCurrentActive
  if (currentChatType?.chatType === CHAT_GPT) {
    onConversation()
  }
  else {
    const currentChatRoomId = chatStore.getChatRoomIdByUuid(currentChatType?.uuid)
    onDiscussing(currentChatRoomId)
  }
}

async function onDiscussing(roomId: string) {
  const message = prompt.value
  const chatType = CHAT_FRIENDS
  const currentAvatar = userStore.$state.userInfo.avatar
  // const roomId = chatStore.$state.chat[0].roomId // å‡è®¾ä½ æ­£åœ¨ä¸ç¬¬ä¸€ä¸ªèŠå¤©å®¤è¿›è¡Œå¯¹è¯

  if (loading.value)
    return

  if (!message || message.trim() === '')
    return

  addChat(
    +uuid,
    chatType,
    {
      nickName: currentChat?.nickName,
      dateTime: new Date().toLocaleString(),
      text: message,
      inversion: true,
      hasAvatar: true,
      isleft: false,
      error: false,
      conversationOptions: null,
      requestOptions: { prompt: message, options: null },
    },
  )
  scrollToBottom()

  loading.value = true
  prompt.value = ''

  // å‘é€æ¶ˆæ¯åˆ°æœåŠ¡å™¨
  // socket.emit('sendMessage', { roomId, message })
  emitSendMessage(roomId, currentChat?.nickName, currentAvatar, message)
  onReceiveMessage(roomId, uuid, message, scrollToBottom)
  // globalThis.console.log(`send ${message} to [${roomId}], over~`)

  loading.value = false
}

async function onConversation() {
  let message = prompt.value
  const chatType = CHAT_GPT
  if (loading.value)
    return

  if (!message || message.trim() === '')
    return

  controller = new AbortController()

  addChat(
    +uuid,
    chatType,
    {
      nickName: GPTnickName,
      dateTime: new Date().toLocaleString(),
      text: message,
      inversion: true,
      hasAvatar: false,
      isleft: true,
      error: false,
      conversationOptions: null,
      requestOptions: { prompt: message, options: null },
    },
  )
  scrollToBottom()

  loading.value = true
  prompt.value = ''

  let options: Chat.ConversationRequest = {}
  const lastContext = conversationList.value[conversationList.value.length - 1]?.conversationOptions

  if (lastContext && usingContext.value)
    options = { ...lastContext }

  addChat(
    +uuid,
    chatType,
    {
      nickName: GPTnickName,
      dateTime: new Date().toLocaleString(),
      text: '',
      loading: true,
      inversion: false,
      hasAvatar: false,
      isleft: true,
      error: false,
      conversationOptions: null,
      requestOptions: { prompt: message, options: { ...options } },
    },
  )
  scrollToBottom()

  try {
    let lastText = ''
    const fetchChatAPIOnce = async () => {
      await fetchChatAPIProcess<Chat.ConversationResponse>({
        prompt: message,
        options,
        signal: controller.signal,
        onDownloadProgress: ({ event }) => {
          const xhr = event.target
          const { responseText } = xhr
          // Always process the final line
          const lastIndex = responseText.lastIndexOf('\n', responseText.length - 2)
          let chunk = responseText
          if (lastIndex !== -1)
            chunk = responseText.substring(lastIndex)
          try {
            const data = JSON.parse(chunk)
            updateChat(
              +uuid,
              dataSources.value.length - 1,
              {
                nickName: GPTnickName,
                dateTime: new Date().toLocaleString(),
                text: lastText + (data.text ?? ''),
                inversion: false,
                hasAvatar: false,
                isleft: true,
                error: false,
                loading: true,
                conversationOptions: { conversationId: data.conversationId, parentMessageId: data.id },
                requestOptions: { prompt: message, options: { ...options } },
              },
            )

            if (openLongReply && data.detail.choices[0].finish_reason === 'length') {
              options.parentMessageId = data.id
              lastText = data.text
              message = ''
              return fetchChatAPIOnce()
            }

            scrollToBottomIfAtBottom()
          }
          catch (error) {
            //
          }
        },
      })
      updateChatSome(+uuid, dataSources.value.length - 1, { loading: false })
    }

    await fetchChatAPIOnce()
  }
  catch (error: any) {
    const errorMessage = error?.message ?? t('common.wrong')

    if (error.message === 'canceled') {
      updateChatSome(
        +uuid,
        dataSources.value.length - 1,
        {
          loading: false,
        },
      )
      scrollToBottomIfAtBottom()
      return
    }

    const currentChat = getChatByUuidAndIndex(+uuid, dataSources.value.length - 1)

    if (currentChat?.text && currentChat.text !== '') {
      updateChatSome(
        +uuid,
        dataSources.value.length - 1,
        {
          text: `${currentChat.text}\n[${errorMessage}]`,
          error: false,
          loading: false,
        },
      )
      return
    }

    updateChat(
      +uuid,
      dataSources.value.length - 1,
      {
        nickName: GPTnickName,
        dateTime: new Date().toLocaleString(),
        text: errorMessage,
        inversion: false,
        hasAvatar: false,
        isleft: true,
        error: true,
        loading: false,
        conversationOptions: null,
        requestOptions: { prompt: message, options: { ...options } },
      },
    )
    scrollToBottomIfAtBottom()
  }
  finally {
    loading.value = false
  }
}

async function onRegenerate(index: number) {
  if (loading.value)
    return

  controller = new AbortController()

  const { requestOptions } = dataSources.value[index]

  let message = requestOptions?.prompt ?? ''

  let options: Chat.ConversationRequest = {}

  if (requestOptions.options)
    options = { ...requestOptions.options }

  loading.value = true

  updateChat(
    +uuid,
    index,
    {
      nickName: GPTnickName,
      dateTime: new Date().toLocaleString(),
      text: '',
      inversion: false,
      hasAvatar: false,
      isleft: true,
      error: false,
      loading: true,
      conversationOptions: null,
      requestOptions: { prompt: message, options: { ...options } },
    },
  )

  try {
    let lastText = ''
    const fetchChatAPIOnce = async () => {
      await fetchChatAPIProcess<Chat.ConversationResponse>({
        prompt: message,
        options,
        signal: controller.signal,
        onDownloadProgress: ({ event }) => {
          const xhr = event.target
          const { responseText } = xhr
          // Always process the final line
          const lastIndex = responseText.lastIndexOf('\n', responseText.length - 2)
          let chunk = responseText
          if (lastIndex !== -1)
            chunk = responseText.substring(lastIndex)
          try {
            const data = JSON.parse(chunk)
            updateChat(
              +uuid,
              index,
              {
                nickName: GPTnickName,
                dateTime: new Date().toLocaleString(),
                text: lastText + (data.text ?? ''),
                inversion: false,
                hasAvatar: false,
                isleft: true,
                error: false,
                loading: true,
                conversationOptions: { conversationId: data.conversationId, parentMessageId: data.id },
                requestOptions: { prompt: message, options: { ...options } },
              },
            )

            if (openLongReply && data.detail.choices[0].finish_reason === 'length') {
              options.parentMessageId = data.id
              lastText = data.text
              message = ''
              return fetchChatAPIOnce()
            }
          }
          catch (error) {
            //
          }
        },
      })
      updateChatSome(+uuid, index, { loading: false })
    }
    await fetchChatAPIOnce()
  }
  catch (error: any) {
    if (error.message === 'canceled') {
      updateChatSome(
        +uuid,
        index,
        {
          loading: false,
        },
      )
      return
    }

    const errorMessage = error?.message ?? t('common.wrong')

    updateChat(
      +uuid,
      index,
      {
        nickName: GPTnickName,
        dateTime: new Date().toLocaleString(),
        text: errorMessage,
        inversion: false,
        hasAvatar: false,
        isleft: true,
        error: true,
        loading: false,
        conversationOptions: null,
        requestOptions: { prompt: message, options: { ...options } },
      },
    )
  }
  finally {
    loading.value = false
  }
}

function handleExport() {
  if (loading.value)
    return

  const d = dialog.warning({
    title: t('chat.exportImage'),
    content: t('chat.exportImageConfirm'),
    positiveText: t('common.yes'),
    negativeText: t('common.no'),
    onPositiveClick: async () => {
      try {
        d.loading = true
        const ele = document.getElementById('image-wrapper')
        const canvas = await html2canvas(ele as HTMLDivElement, {
          useCORS: true,
        })
        const imgUrl = canvas.toDataURL('image/png')
        const tempLink = document.createElement('a')
        tempLink.style.display = 'none'
        tempLink.href = imgUrl
        tempLink.setAttribute('download', 'chat-shot.png')
        if (typeof tempLink.download === 'undefined')
          tempLink.setAttribute('target', '_blank')

        document.body.appendChild(tempLink)
        tempLink.click()
        document.body.removeChild(tempLink)
        window.URL.revokeObjectURL(imgUrl)
        d.loading = false
        ms.success(t('chat.exportSuccess'))
        Promise.resolve()
      }
      catch (error: any) {
        ms.error(t('chat.exportFailed'))
      }
      finally {
        d.loading = false
      }
    },
  })
}

function handleDelete(index: number) {
  if (loading.value)
    return

  dialog.warning({
    title: t('chat.deleteMessage'),
    content: t('chat.deleteMessageConfirm'),
    positiveText: t('common.yes'),
    negativeText: t('common.no'),
    onPositiveClick: () => {
      chatStore.deleteChatByUuid(+uuid, index)
    },
  })
}

function handleClear() {
  if (loading.value)
    return

  dialog.warning({
    title: t('chat.clearChat'),
    content: t('chat.clearChatConfirm'),
    positiveText: t('common.yes'),
    negativeText: t('common.no'),
    onPositiveClick: () => {
      chatStore.clearChatByUuid(+uuid)
    },
  })
}

function handleEnter(event: KeyboardEvent) {
  if (!isMobile.value) {
    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault()
      handleSubmit()
    }
  }
  else {
    if (event.key === 'Enter' && event.ctrlKey) {
      event.preventDefault()
      handleSubmit()
    }
  }
}

function handleStop() {
  if (loading.value) {
    controller.abort()
    loading.value = false
  }
}

// å¯ä¼˜åŒ–éƒ¨åˆ†
// æœç´¢é€‰é¡¹è®¡ç®—ï¼Œè¿™é‡Œä½¿ç”¨valueä½œä¸ºç´¢å¼•é¡¹ï¼Œæ‰€ä»¥å½“å‡ºç°é‡å¤valueæ—¶æ¸²æŸ“å¼‚å¸¸(å¤šé¡¹åŒæ—¶å‡ºç°é€‰ä¸­æ•ˆæœ)
// ç†æƒ³çŠ¶æ€ä¸‹å…¶å®åº”è¯¥æ˜¯keyä½œä¸ºç´¢å¼•é¡¹,ä½†å®˜æ–¹çš„renderOptionä¼šå‡ºç°é—®é¢˜ï¼Œæ‰€ä»¥å°±éœ€è¦valueårenderLabelå®ç°
const searchOptions = computed(() => {
  if (prompt.value.startsWith('/')) {
    return promptTemplate.value.filter((item: { key: string }) => item.key.toLowerCase().includes(prompt.value.substring(1).toLowerCase())).map((obj: { value: any }) => {
      return {
        label: obj.value,
        value: obj.value,
      }
    })
  }
  else {
    return []
  }
})

// valueåæ¸²æŸ“key
const renderOption = (option: { label: string }) => {
  for (const i of promptTemplate.value) {
    if (i.value === option.label)
      return [i.key]
  }
  return []
}

const placeholder = computed(() => {
  if (isMobile.value)
    return t('chat.placeholderMobile')
  return t('chat.placeholder')
})

const buttonDisabled = computed(() => {
  return loading.value || !prompt.value || prompt.value.trim() === ''
})

const footerClass = computed(() => {
  let classes = ['p-4']
  if (isMobile.value)
    classes = ['sticky', 'left-0', 'bottom-0', 'right-0', 'p-2', 'pr-3', 'overflow-hidden']
  return classes
})

// onBeforeMount(() => {
//   reConnect(currentChat.nickName, currentChat.roomId)
// })

onMounted(() => {
  // if (window.performance.navigation.type === 1)
  //   reConnect(currentChat.nickName, currentChat.roomId)
  const performanceEntries = performance.getEntriesByType('navigation')
  for (let i = 0; i < performanceEntries.length; i++) {
    const navigationEntry = performanceEntries[i] as PerformanceNavigationTiming
    if (navigationEntry.type === 'reload') {
      reconnect(currentChat.nickName, currentChat.roomId)
      break
    }
  }

  onConnect()
  const currentChatType = chatStore.getChatHistoryByCurrentActive
  const currentChatRoomId = chatStore.getChatRoomIdByUuid(currentChatType?.uuid)
  onReceiveMessage(currentChatRoomId, uuid, prompt.value, scrollToBottom)
  onRoomNotExist(dialog)
  onUserDisconnect(ms)
  onUserJoined(uuid)
  onUserLeft(uuid)

  scrollToBottom()
  if (inputRef.value && !isMobile.value)
    inputRef.value?.focus()
})

onUnmounted(() => {
  if (loading.value)
    controller.abort()
})
</script>

<template>
  <div class="flex flex-col w-full h-full">
    <HeaderComponent
      v-if="isMobile"
      :using-context="usingContext"
      @export="handleExport"
      @toggle-using-context="toggleUsingContext"
    />
    <main class="flex-1 overflow-hidden">
      <div id="scrollRef" ref="scrollRef" class="h-full overflow-hidden overflow-y-auto">
        <div
          id="image-wrapper"
          class="w-full max-w-screen-xl m-auto dark:bg-[#101014]"
          :class="[isMobile ? 'p-2' : 'p-4']"
        >
          <template v-if="!dataSources.length">
            <div class="flex items-center justify-center mt-4 text-center text-neutral-300">
              <SvgIcon icon="ri:bubble-chart-fill" class="mr-2 text-3xl" />
              <span>Aha~</span>
            </div>
          </template>
          <template v-else>
            <div>
              <Message
                v-for="(item, index) of dataSources"
                :key="index"
                :issrc="false"
                :avatar="item.avatar"
                :nickname="item.nickName"
                :date-time="item.dateTime"
                :text="item.text"
                :inversion="item.inversion"
                :has-avatar="item.hasAvatar"
                :isleft="item.isleft"
                :error="item.error"
                :loading="item.loading"
                @regenerate="onRegenerate(index)"
                @delete="handleDelete(index)"
              />
              <div class="sticky bottom-0 left-0 flex justify-center">
                <NButton v-if="loading" type="warning" @click="handleStop">
                  <template #icon>
                    <SvgIcon icon="ri:stop-circle-line" />
                  </template>
                  Stop Responding
                </NButton>
              </div>
            </div>
          </template>
        </div>
      </div>
    </main>
    <footer :class="footerClass">
      <div class="w-full max-w-screen-xl m-auto">
        <div class="flex items-center justify-between space-x-2">
          <HoverButton v-if="chatTypeRef === CHAT_GPT" @click="handleClear">
            <span class="text-xl text-[#4f555e] dark:text-white">
              <SvgIcon icon="ri:delete-bin-line" />
            </span>
          </HoverButton>
          <HoverButton v-if="!isMobile && chatTypeRef === CHAT_GPT" @click="handleExport">
            <span class="text-xl text-[#4f555e] dark:text-white">
              <SvgIcon icon="ri:download-2-line" />
            </span>
          </HoverButton>
          <HoverButton v-if="!isMobile && chatTypeRef === CHAT_GPT" @click="toggleUsingContext">
            <span class="text-xl" :class="{ 'text-[#4b9e5f]': usingContext, 'text-[#a8071a]': !usingContext }">
              <SvgIcon icon="ri:chat-history-line" />
            </span>
          </HoverButton>
          <NAutoComplete v-if="chatTypeRef === CHAT_GPT" v-model:value="prompt" :options="searchOptions" :render-label="renderOption">
            <template #default="{ handleInput, handleBlur, handleFocus }">
              <NInput
                ref="inputRef"
                v-model:value="prompt"
                type="textarea"
                :placeholder="placeholder"
                :autosize="{ minRows: 1, maxRows: isMobile ? 4 : 8 }"
                @input="handleInput"
                @focus="handleFocus"
                @blur="handleBlur"
                @keypress="handleEnter"
              />
            </template>
          </NAutoComplete>
          <MdEditor
            v-else
            v-model="prompt"
            no-upload-img
            style="height: 300px;"
            placeholder="ğŸš€ğŸš€ğŸš€ç¼–è¾‘Markdownæ¥å‘é€æ¶ˆæ¯å§~"
            :theme="theme"
            :toolbars="['bold', 'underline', 'italic', '-', 'title', 'strikeThrough', 'sub', 'sup', 'quote', 'unorderedList', 'orderedList', 'task', '-', 'codeRow', 'code', 'link', 'table', 'mermaid', 'katex', '-', 'revoke', 'next', '=', 'pageFullscreen', 'fullscreen', 'preview', 'catalog', 'github']"
            :max-length="5000"
            :preview="true"
          />
          <NButton type="primary" :disabled="buttonDisabled" @click="handleSubmit">
            <template #icon>
              <span class="dark:text-black">
                <SvgIcon icon="ri:send-plane-fill" />
              </span>
            </template>
          </NButton>
        </div>
      </div>
    </footer>
  </div>
</template>
